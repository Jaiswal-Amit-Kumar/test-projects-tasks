import sys
from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer
from langdetect import detect
import torch

class CallAnalyzer:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"âš™ï¸ Using device: {self.device}")
        
        # Load models that don't require authentication
        self.sentiment_pipe = pipeline(
            "text-classification",
            model="blanchefort/rubert-base-cased-sentiment",
            device=self.device
        )
        
        # Alternative translation model that doesn't need sacremoses
        self.translation_pipe = pipeline(
            "translation",
            model="Helsinki-NLP/opus-mt-ru-en",
            device=self.device
        )
        
        # Using a public model for analysis
        self.analysis_model = AutoModelForSeq2SeqLM.from_pretrained("IlyaGusev/saiga_llama3_8b")
        self.analysis_tokenizer = AutoTokenizer.from_pretrained("IlyaGusev/saiga_llama3_8b")
        self.analysis_model = self.analysis_model.to(self.device)

    def analyze_call(self, transcript_path: str) -> dict:
        """Main analysis function"""
        transcript = self._read_transcript(transcript_path)
        lang = detect(transcript)
        
        print(f"ğŸŒ Detected language: {lang}")
        
        # Ensure we have Russian text
        if lang != "ru":
            translated = self._translate_to_russian(transcript)
        else:
            translated = transcript
            
        sentiment = self._analyze_sentiment(translated)
        analysis = self._generate_analysis(translated)
        
        return {
            "sentiment": sentiment,
            "analysis": analysis,
            "language": lang
        }

    def _read_transcript(self, path: str) -> str:
        """Read transcript from file"""
        with open(path, "r", encoding="utf-8") as f:
            return f.read()

    def _analyze_sentiment(self, text: str) -> dict:
        """Analyze sentiment with Russian-specific model"""
        print("ğŸ“Š Analyzing sentiment...")
        result = self.sentiment_pipe(text[:1000])  # Limit to first 1000 chars
        return {
            "label": result[0]["label"],
            "score": result[0]["score"]
        }

    def _generate_analysis(self, text: str) -> str:
        """Generate detailed call analysis in Russian"""
        print("ğŸ§  Generating professional analysis...")
        
        prompt = f"""
Ğ¢Ñ‹ - Ğ¾Ğ¿Ñ‹Ñ‚Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ğº ĞºĞ¾Ğ»Ğ»-Ñ†ĞµĞ½Ñ‚Ñ€Ğ°. ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ ÑÑ‚Ğ¾Ñ‚ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€:

{text[:2000]}

Ğ”Ğ°Ğ¹Ñ‚Ğµ Ñ€Ğ°Ğ·Ğ²ĞµÑ€Ğ½ÑƒÑ‚Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ:
1. ĞÑ†ĞµĞ½ĞºÑƒ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ° (1-5)
2. Ğ¡Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ñ‹
3. Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ
4. ĞĞ½Ğ°Ğ»Ğ¸Ğ· ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ‚Ğ¾Ğ½Ğ°
5. ĞšĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ ÑĞ¾Ğ²ĞµÑ‚Ñ‹ Ğ¿Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ

ĞÑ‚Ğ²ĞµÑ‚:
"""
        inputs = self.analysis_tokenizer(
            prompt,
            return_tensors="pt",
            max_length=1024,
            truncation=True
        ).to(self.device)
        
        outputs = self.analysis_model.generate(
            **inputs,
            max_new_tokens=512,
            temperature=0.7,
            top_p=0.9,
            do_sample=True
        )
        
        return self.analysis_tokenizer.decode(outputs[0], skip_special_tokens=True)

    def _translate_to_russian(self, text: str) -> str:
        """Translate text to Russian if needed"""
        print("ğŸ”„ Translating to Russian...")
        return self.translation_pipe(text[:1000])[0]["translation_text"]

def main():
    if len(sys.argv) < 2:
        print("Usage: python call_analyzer.py <transcript_file.txt>")
        return
    
    analyzer = CallAnalyzer()
    results = analyzer.analyze_call(sys.argv[1])
    
    print("\n====================")
    print("ğŸ“ Professional Call Analysis")
    print("====================")
    print(f"ğŸ“Š Sentiment: {results['sentiment']['label']} (confidence: {results['sentiment']['score']:.2f})")
    print(f"ğŸŒ Language: {results['language']}")
    print("\nğŸ” Detailed Analysis:")
    print(results["analysis"])
    
    with open("call_analysis_report.txt", "w", encoding="utf-8") as f:
        f.write(str(results))

if __name__ == "__main__":
    main()